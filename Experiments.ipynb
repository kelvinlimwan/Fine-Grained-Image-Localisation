{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9edd730",
   "metadata": {},
   "outputs": [],
   "source": [
    "### PACKAGES\n",
    "import csv\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import time\n",
    "from copy import deepcopy\n",
    "from asift import *\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from find_obj import init_feature, filter_matches, explore_match\n",
    "from scipy import ndimage \n",
    "from skimage import transform\n",
    "from skimage.transform import warp, ProjectiveTransform\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "from netvlad_keras import *\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0a765db",
   "metadata": {},
   "outputs": [],
   "source": [
    "### CONSTANTS\n",
    "ROOTPATH = './'\n",
    "IMG_HEIGHT = 128\n",
    "IMG_WIDTH = 128\n",
    "NUM_CHANNELS = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98056da",
   "metadata": {},
   "source": [
    "### Import Training and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f0b3f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_names = [] # list of train image names as strings\n",
    "train_img_labels = [] # list of train images labels as tuples (latitude, longitude)\n",
    "with open('COMP90086_2021_Project_train/train.csv') as train_csv:\n",
    "    reader = csv.reader(train_csv, delimiter=',')\n",
    "    next(reader) # skip header row\n",
    "    for row in reader:\n",
    "        name = row[0] # string\n",
    "        label = (float(row[1]), float(row[2])) # tuple\n",
    "        train_img_names.append(name)\n",
    "        train_img_labels.append(label)\n",
    "\n",
    "# train images stored as numpy array\n",
    "train_size = (len(train_img_names), IMG_HEIGHT, IMG_WIDTH,NUM_CHANNELS )\n",
    "train_images = np.zeros(train_size, dtype='uint8')\n",
    "for i in range(len(train_img_names)):\n",
    "    name = train_img_names[i]\n",
    "    subpath = 'COMP90086_2021_Project_train/train/' + name + '.jpg'\n",
    "    img = cv2.imread(os.path.join(ROOTPATH, subpath))\n",
    "    img = cv2.resize(img,(IMG_WIDTH,IMG_HEIGHT))\n",
    "    train_images[i] = img\n",
    "\n",
    "# train labels stored as numpy array\n",
    "train_labels = np.array(train_img_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b88c9e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img_names = [] # list of test image names as strings\n",
    "with open('COMP90086_2021_Project_test/imagenames.csv') as test_csv:\n",
    "    reader = csv.reader(test_csv, delimiter=',')\n",
    "    next(reader) # skip header row\n",
    "    for row in reader:\n",
    "        name = row[0] # string\n",
    "        test_img_names.append(name)\n",
    "        \n",
    "# test images stored as numpy array\n",
    "test_size = (len(test_img_names), IMG_HEIGHT, IMG_WIDTH, NUM_CHANNELS)\n",
    "test_images = np.zeros(test_size, dtype='uint8')\n",
    "for i in range(len(test_img_names)):\n",
    "    name = test_img_names[i]\n",
    "    subpath = 'COMP90086_2021_Project_test/test/' + name + '.jpg'\n",
    "    img = cv2.imread(os.path.join(ROOTPATH, subpath))\n",
    "    img = cv2.resize(img,(IMG_WIDTH,IMG_HEIGHT))\n",
    "    test_images[i] = img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d36257",
   "metadata": {},
   "source": [
    "### Baseline CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1531f542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 126, 126, 32)      896       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 124, 124, 16)      4624      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 124, 124, 16)      272       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 124, 124, 2)       34        \n",
      "=================================================================\n",
      "Total params: 5,826\n",
      "Trainable params: 5,826\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "6750/6750 [==============================] - 18s 2ms/step - loss: 40.9270 - val_loss: 39.1598\n",
      "Epoch 2/20\n",
      "6750/6750 [==============================] - 16s 2ms/step - loss: 40.3211 - val_loss: 38.3868\n",
      "Epoch 3/20\n",
      "6750/6750 [==============================] - 16s 2ms/step - loss: 39.8695 - val_loss: 38.9155\n",
      "Epoch 4/20\n",
      "6750/6750 [==============================] - 16s 2ms/step - loss: 39.6830 - val_loss: 38.2565\n",
      "Epoch 5/20\n",
      "6750/6750 [==============================] - 16s 2ms/step - loss: 39.5098 - val_loss: 38.1831\n",
      "Epoch 6/20\n",
      "6750/6750 [==============================] - 16s 2ms/step - loss: 39.3209 - val_loss: 38.2711\n",
      "Epoch 7/20\n",
      "6750/6750 [==============================] - 16s 2ms/step - loss: 39.4061 - val_loss: 37.9518\n",
      "Epoch 8/20\n",
      "6750/6750 [==============================] - 16s 2ms/step - loss: 39.0861 - val_loss: 37.6117\n",
      "Epoch 9/20\n",
      "6750/6750 [==============================] - 16s 2ms/step - loss: 38.8595 - val_loss: 37.4487\n",
      "Epoch 10/20\n",
      "6750/6750 [==============================] - 17s 2ms/step - loss: 38.6335 - val_loss: 37.1977\n",
      "Epoch 11/20\n",
      "6750/6750 [==============================] - 16s 2ms/step - loss: 38.6391 - val_loss: 37.6281\n",
      "Epoch 12/20\n",
      "6750/6750 [==============================] - 16s 2ms/step - loss: 38.5922 - val_loss: 37.5764\n",
      "Epoch 13/20\n",
      "6750/6750 [==============================] - 16s 2ms/step - loss: 38.0598 - val_loss: 36.6376\n",
      "Epoch 14/20\n",
      "6750/6750 [==============================] - 16s 2ms/step - loss: 37.9818 - val_loss: 36.6133\n",
      "Epoch 15/20\n",
      "6750/6750 [==============================] - 16s 2ms/step - loss: 37.9477 - val_loss: 37.2543\n",
      "Epoch 16/20\n",
      "6750/6750 [==============================] - 16s 2ms/step - loss: 37.8553 - val_loss: 36.4299\n",
      "Epoch 17/20\n",
      "6750/6750 [==============================] - 16s 2ms/step - loss: 37.6669 - val_loss: 36.1525\n",
      "Epoch 18/20\n",
      "6750/6750 [==============================] - 16s 2ms/step - loss: 37.4850 - val_loss: 36.6246\n",
      "Epoch 19/20\n",
      "6750/6750 [==============================] - 16s 2ms/step - loss: 37.4036 - val_loss: 36.2854\n",
      "Epoch 20/20\n",
      "6750/6750 [==============================] - 16s 2ms/step - loss: 37.3463 - val_loss: 36.2644\n"
     ]
    }
   ],
   "source": [
    "baseline = keras.models.Sequential()\n",
    "\n",
    "baseline.add(layers.Input((IMG_HEIGHT, IMG_WIDTH, NUM_CHANNELS)))\n",
    "baseline.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "baseline.add(layers.Conv2D(16, (3, 3), activation='relu'))\n",
    "baseline.add(layers.Dense(16, activation='relu'))\n",
    "baseline.add(layers.Dense(2))\n",
    "\n",
    "op = keras.optimizers.Adam()\n",
    "baseline.compile(loss='mae', optimizer=op)\n",
    "\n",
    "baseline.summary()\n",
    "\n",
    "h = baseline.fit(train_images, train_labels,verbose = 1,batch_size=1,validation_split = 0.1,epochs = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b2e202",
   "metadata": {},
   "source": [
    "## EXPERIMENTS FOR PAPER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76afeb7",
   "metadata": {},
   "source": [
    "### FEATURE EXTRACTION: SIFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21865482",
   "metadata": {},
   "outputs": [],
   "source": [
    "sift = cv2.SIFT_create() # initialise SIFT detector\n",
    "sift_train_features = []\n",
    "for i in range(len(train_images)):    \n",
    "    train_image = train_images[i]\n",
    "    # convert test image to grayscale\n",
    "    gray_train_image = cv2.cvtColor(train_image, cv2.COLOR_BGR2GRAY)\n",
    "    # SIFT keypoints and descriptors for test image\n",
    "    _, desc = sift.detectAndCompute(gray_train_image, None)\n",
    "    sift_train_features.append(desc)\n",
    "    \n",
    "with open(os.path.join(os.getcwd(),\"feature_extraction/sift_train_feat.pickle\"),'wb') as handle:\n",
    "    pickle.dump(sift_train_features, handle, protocol=pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15fde94a",
   "metadata": {},
   "source": [
    "### FEATURE EXTRACTION: ASIFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14e162f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization\n",
    "detector, matcher = init_feature(\"sift-flann\")\n",
    "pool=ThreadPool(processes = cv.getNumberOfCPUs())\n",
    "\n",
    "asift_desc_features = [] # Save feature descriptions\n",
    "asift_kp_feaures = [] # Save description key points\n",
    "\n",
    "\n",
    "for i in range(len(train_images)):    \n",
    "    train_image = train_images[i]\n",
    "    gray_test_image = cv2.cvtColor(train_image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # ASIFT keypoints and descriptors for test image\n",
    "    kp1, desc1 = affine_detect(detector, gray_test_image, pool=pool)\n",
    "    \n",
    "    # Cant Pickle (Save) cv2.keypoint directly, so we need to first serialize it \n",
    "    serialize_list = []\n",
    "    for kp in kp1:\n",
    "        temp = (kp.pt, kp.size, kp.angle, kp.response, kp.octave, kp.class_id) \n",
    "        serialize_list.append(temp)\n",
    "\n",
    "    asift_desc_features.append(desc1)\n",
    "    asift_kp_feaures.append(serialize_list)\n",
    "\n",
    "# Pickle to save to disk \n",
    "with open(os.path.join(os.getcwd(),\"feature_extraction/asift_train_feat.pickle\"),'wb') as handle:\n",
    "    pickle.dump(asift_desc_features, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open(os.path.join(os.getcwd(),\"feature_extraction/asift_kp_train_feat.pickle\"),'wb') as handle:\n",
    "    pickle.dump(asift_kp_feaures, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3b92bf",
   "metadata": {},
   "source": [
    "### FEATURE EXTRACTION: NetVLAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a763c30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kazuy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:355: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "substract_average (Substract (None, 128, 128, 3)       3         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 128, 128, 64)      1792      \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 128, 128, 64)      36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 64, 64, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 64, 64, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 32, 32, 256)       295168    \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 32, 32, 256)       590080    \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 32, 32, 256)       590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 16, 16, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "lambda (Lambda)              (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "net_vlad (NetVLAD)           (None, 32768)             65536     \n",
      "_________________________________________________________________\n",
      "lambda_1 (Lambda)            (None, 1, 32768)          0         \n",
      "_________________________________________________________________\n",
      "lambda_2 (Lambda)            (None, 1, 1, 32768)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 1, 1, 4096)        134221824 \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "lambda_3 (Lambda)            (None, 4096)              0         \n",
      "=================================================================\n",
      "Total params: 149,002,051\n",
      "Trainable params: 149,002,048\n",
      "Non-trainable params: 3\n",
      "_________________________________________________________________\n",
      "Time Taken:  7.571038007736206\n"
     ]
    }
   ],
   "source": [
    "netvlad_model = NetVLADModel(input_shape=(IMG_HEIGHT, IMG_WIDTH, NUM_CHANNELS)) # Define input layer\n",
    "\n",
    "netvlad_model.summary()\n",
    "netvlad_model.load_weights('checkpoint/netvlad_weights.h5')\n",
    "netvlad_model.build()\n",
    "\n",
    "# Extract features\n",
    "start= time.time()\n",
    "train_features = netvlad_model.predict(train_images)\n",
    "end= time.time()\n",
    "with open(os.path.join(os.getcwd(),\"feature_extraction/vlad_train_feat.pickle\"),'wb') as handle:\n",
    "    pickle.dump(train_features, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "print(\"Time Taken: \",end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d094ffd",
   "metadata": {},
   "source": [
    "### FEATURE EXTRACTION: Self-Supervised Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "653da4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train images stored as numpy array\n",
    "train_size = (len(train_img_names), 128, 128 ,NUM_CHANNELS )\n",
    "train_images_ss = np.zeros(train_size, dtype='uint8')\n",
    "for i in range(len(train_img_names)):\n",
    "    name = train_img_names[i]\n",
    "    subpath = 'COMP90086_2021_Project_train/train/' + name + '.jpg'\n",
    "    img = cv2.imread(os.path.join(ROOTPATH, subpath))\n",
    "    img = cv2.resize(img,(128,128))\n",
    "    train_images_ss[i] = img\n",
    "train_images_ss = train_images_ss.astype(float)/255\n",
    "# train labels stored as numpy array\n",
    "train_labels_ss = np.array(train_img_labels)\n",
    "\n",
    "\n",
    "# test images stored as numpy array\n",
    "test_size = (len(test_img_names), 128, 128, NUM_CHANNELS)\n",
    "test_images_ss = np.zeros(test_size, dtype='uint8')\n",
    "for i in range(len(test_img_names)):\n",
    "    name = test_img_names[i]\n",
    "    subpath = 'COMP90086_2021_Project_test/test/' + name + '.jpg'\n",
    "    img = cv2.imread(os.path.join(ROOTPATH, subpath))\n",
    "    img = cv2.resize(img,(128,128))\n",
    "    test_images_ss[i] = img\n",
    "test_images_ss = test_images_ss.astype(float)/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a76286b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_extraction_method: choose from \"SS ROT\" or \"SS WARP\"\n",
    "feature_extraction_method = \"SS ROT\"\n",
    "\n",
    "# shuffle training instances\n",
    "idx = np.random.randint(train_images_ss.shape[0], size=train_images_ss.shape[0])\n",
    "train_images_ss_shuffled = train_images[idx,:,:,:]\n",
    "train_labels_ss_shuffled = train_labels[idx,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce4ef94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if feature_extraction_method == \"SS WARP\": # Self Supervised With Warping\n",
    "    train_images_warp=np.zeros_like(train_images_ss_shuffled)  \n",
    "    train_label_warp=np.zeros((train_labels_ss_shuffled.shape[0],1) ) \n",
    "elif feature_extraction_method == \"SS ROT\": # Self Supervised With Warping\n",
    "    train_images_rot=np.zeros_like(train_images_ss_shuffled)  \n",
    "    train_label_rot=np.zeros((train_labels_ss_shuffled.shape[0],1) )\n",
    "    \n",
    "#0: no warping, 1 warp right, 2 warp left, 3 warp top, 4 warp bottom\n",
    "for i in range (train_images_ss_shuffled.shape[0]):\n",
    "    \n",
    "    img= train_images_ss_shuffled[i,:,:,:] \n",
    "    \n",
    "    if feature_extraction_method == \"SS ROT\":\n",
    "        \n",
    "        if np.mod(i,4)==0:\n",
    "            rot_img = img \n",
    "            rot_lab=0\n",
    "        elif np.mod(i,4)==1:\n",
    "            rot_img = ndimage.rotate(img, 90)\n",
    "            rot_lab=1\n",
    "        elif np.mod(i,4)==2:\n",
    "            rot_img = ndimage.rotate(img, 180)\n",
    "            rot_lab=2\n",
    "        else:\n",
    "            rot_img = ndimage.rotate(img, 270)\n",
    "            rot_lab=3\n",
    "            \n",
    "        train_images_rot[i,:,:,:] = rot_img\n",
    "        train_label_rot[i,0]=rot_lab\n",
    "    \n",
    "    elif feature_extraction_method == \"SS WARP\":\n",
    "        \n",
    "        if np.mod(i,5)==0:\n",
    "            warped_img = img \n",
    "            warped_label = 0\n",
    "        elif np.mod(i,5)==1:\n",
    "            warped_img = warp(img, transform_right)\n",
    "            warped_label=1\n",
    "        elif np.mod(i,5)==2:\n",
    "            warped_img = warp(img, transform_left)\n",
    "            warped_label=2\n",
    "        elif np.mod(i,5)==3:\n",
    "            warped_img = warp(img, transform_top)\n",
    "            warped_label=3\n",
    "        else:\n",
    "            warped_img = warp(img, transform_bottom)\n",
    "            warped_label=4\n",
    "\n",
    "        train_images_warp[i,:,:,:] = warped_img\n",
    "        train_label_warp[i,0]=warped_label\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b4b457e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_16 (Conv2D)           (None, 126, 126, 16)      448       \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 124, 124, 16)      2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 42, 42, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 40, 40, 32)        4640      \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 38, 38, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 9, 9, 64)          36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 3, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5)                 1285      \n",
      "=================================================================\n",
      "Total params: 139,157\n",
      "Trainable params: 139,157\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "60/60 [==============================] - 1s 15ms/step - loss: 1.9373 - accuracy: 0.3057 - val_loss: 1.2647 - val_accuracy: 0.4327\n",
      "Epoch 2/10\n",
      "60/60 [==============================] - 1s 13ms/step - loss: 1.1228 - accuracy: 0.5165 - val_loss: 0.9775 - val_accuracy: 0.6107\n",
      "Epoch 3/10\n",
      "60/60 [==============================] - 1s 13ms/step - loss: 0.9467 - accuracy: 0.6142 - val_loss: 0.8807 - val_accuracy: 0.6567\n",
      "Epoch 4/10\n",
      "60/60 [==============================] - 1s 13ms/step - loss: 0.7982 - accuracy: 0.6837 - val_loss: 0.7296 - val_accuracy: 0.7160\n",
      "Epoch 5/10\n",
      "60/60 [==============================] - 1s 13ms/step - loss: 0.6609 - accuracy: 0.7415 - val_loss: 0.6732 - val_accuracy: 0.7387\n",
      "Epoch 6/10\n",
      "60/60 [==============================] - 1s 13ms/step - loss: 0.5598 - accuracy: 0.7827 - val_loss: 0.6088 - val_accuracy: 0.7673\n",
      "Epoch 7/10\n",
      "60/60 [==============================] - 1s 13ms/step - loss: 0.5191 - accuracy: 0.8013 - val_loss: 0.5831 - val_accuracy: 0.7720\n",
      "Epoch 8/10\n",
      "60/60 [==============================] - 1s 13ms/step - loss: 0.4516 - accuracy: 0.8300 - val_loss: 0.5360 - val_accuracy: 0.7967\n",
      "Epoch 9/10\n",
      "60/60 [==============================] - 1s 13ms/step - loss: 0.4054 - accuracy: 0.8490 - val_loss: 0.4694 - val_accuracy: 0.8240\n",
      "Epoch 10/10\n",
      "60/60 [==============================] - 1s 13ms/step - loss: 0.3355 - accuracy: 0.8788 - val_loss: 0.4948 - val_accuracy: 0.8187\n"
     ]
    }
   ],
   "source": [
    "ss_model = keras.Sequential(\n",
    "    [\n",
    "        layers.Input((IMG_HEIGHT, IMG_WIDTH, 3)),\n",
    "        layers.Conv2D(16, (3, 3), activation='relu'), # 126\n",
    "        layers.Conv2D(16, (3, 3), activation='relu'), # 124\n",
    "        layers.MaxPooling2D((3, 3),padding='same'), # 42\n",
    "   \n",
    "        layers.Conv2D(32, (3, 3), activation='relu'), # 40\n",
    "        layers.Conv2D(32, (3, 3), activation='relu'), # 38\n",
    "        layers.MaxPooling2D((3, 3),padding='same'), # 13\n",
    " \n",
    "        layers.Conv2D(64, (3, 3), activation='relu'), # 11\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'), # 9\n",
    "        layers.MaxPooling2D((3, 3),padding='same'), # 3\n",
    "        layers.MaxPooling2D((2, 2),padding='same'), # 2\n",
    "        \n",
    "        layers.Flatten(),\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.Dense(5, activation='softmax')\n",
    "        #layers.Dense(4, activation='softmax')\n",
    "    ]\n",
    ")\n",
    "\n",
    "ss_model.summary()\n",
    "\n",
    "#compile model\n",
    "loss=keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
    "\n",
    "ss_model.compile(optimizer='adam', loss=[loss], metrics=['accuracy'])\n",
    "history=ss_model.fit(train_images_rot,train_label_rot, verbose = 1,validation_split = 0.2,\n",
    "                           epochs=10, batch_size=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd41a9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use partial model for feature extraction\n",
    "features_model=Model(ss_model.inputs, ss_model.layers[-3].output) \n",
    "\n",
    "train_features = features_model.predict(train_images_ss) # Extract Features\n",
    "\n",
    "file_name = feature_extraction_method.replace(\" \", \"_\").lower()\n",
    "\n",
    "with open(os.path.join(os.getcwd(),\"feature_extraction/{}_train_feat.pickle\".format(file_name)),'wb') as handle:\n",
    "    pickle.dump(train_features, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33770251",
   "metadata": {},
   "source": [
    "### FEATURE MATCHING: SELECT METHOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c07d4a68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Features SIFT\n"
     ]
    }
   ],
   "source": [
    "# feature_config: can choose from \"SIFT\",\"ASIFT\",\"SS ROT\", \"SS WARP\", \"VLAD\"\n",
    "feature_config = \"SIFT\"\n",
    "\n",
    "if feature_config == \"SIFT\": \n",
    "    if os.path.exists('./feature_extraction/sift_train_feat.pickle'):\n",
    "        with open(os.path.join(\"feature_extraction\",\"sift_train_feat.pickle\"),'rb') as handle:\n",
    "            img_features = pickle.load(handle)\n",
    "        print(\"Using Features\",feature_config)\n",
    "        \n",
    "elif feature_config == \"ASIFT\":\n",
    "    if os.path.exists('./feature_extraction/asift_train_feat.pickle') and os.path.exists('./feature_extraction/asift_kp_train_feat.pickle'):\n",
    "        with open(os.path.join(\"feature_extraction\",\"asift_train_feat.pickle\"),'rb') as handle:\n",
    "            img_features = pickle.load(handle)\n",
    "        with open(os.path.join(\"feature_extraction\",\"asift_kp_train_feat.pickle\"),'rb') as handle:\n",
    "            serialized_list = pickle.load(handle)\n",
    "            \n",
    "        # Need to deserialize back into cv2.Keypoint object (we couldnt save Keypoint objects directly using Pickle)\n",
    "        img_kp = []\n",
    "        for img in serialized_list:\n",
    "            tmp_kp_list = []\n",
    "            for kp in img:\n",
    "                temp = cv2.KeyPoint(x=kp[0][0],y=kp[0][1], size=kp[1], angle=kp[2], response=kp[3], octave=kp[4], class_id=kp[5]) \n",
    "                tmp_kp_list.append(temp)\n",
    "            img_kp.append(tmp_kp_list)            \n",
    "        print(\"Using Features\",feature_config)\n",
    "\n",
    "elif feature_config == \"VLAD\": # NetVLAD \n",
    "    if os.path.exists('./feature_extraction/VLAD_train_feat.pickle'):\n",
    "        with open(os.path.join(\"feature_extraction\",\"VLAD_train_feat.pickle\"),'rb') as handle:\n",
    "            img_features = pickle.load(handle)\n",
    "        print(\"Using Features\",feature_config)\n",
    "\n",
    "elif feature_config == \"SS ROT\": # Self-supervised (Rotation)\n",
    "    if os.path.exists('./feature_extraction/ss_rot_train_feat.pickle'):\n",
    "        with open(os.path.join(\"feature_extraction\",\"ss_rot_train_feat.pickle\"),'rb') as handle:\n",
    "            img_features = pickle.load(handle)\n",
    "\n",
    "        print(\"Using Features\",feature_config)\n",
    "\n",
    "elif feature_config == \"SS WARP\": #Self-supervised (Warp)\n",
    "    if os.path.exists('./feature_extraction/ss_warp_train_feat.pickle'):\n",
    "        with open(os.path.join(\"feature_extraction\",\"ss_warp_train_feat.pickle\"),'rb') as handle:\n",
    "            img_features = pickle.load(handle)\n",
    "\n",
    "        print(\"Using Features\",feature_config)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff92c17d",
   "metadata": {},
   "source": [
    "### FEATURE MATCHING: FLANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "515148c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USING FEATURES SIFT\n",
      "0\n",
      "MAE 270.9\n",
      "Prediction:(11.82,-67.22), Actual:(-82.78,109.08),ERR270.89999995\n",
      "1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_22428/1147177610.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     58\u001b[0m                                     \u001b[1;31m### FOR SIFT ###\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfeature_config\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"SIFT\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m             \u001b[0mmatches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mflann\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mknnMatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvali_descriptors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_descriptors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mk_nn\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Use FLAN for feature matching\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;31m# Create a mask to draw all good matches\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if feature_config == \"VLAD\" or feature_config == \"SS WARP\" or feature_config == \"SS ROT\":\n",
    "    print(\"Cannt use FLANN with {}, please use a different descriptor\".format(feature_config))\n",
    "    assert(False)\n",
    "    \n",
    "\n",
    "print(\"USING FEATURES\",feature_config)\n",
    "\n",
    "# Shuffle Features\n",
    "idx = np.random.randint(len(img_features), size=len(img_features)) # Scramble index values\n",
    "img_shuffled = [img_features[i] for i in idx] # Shuffle descriptors\n",
    "labels_shuffled = [train_labels[i] for i in idx] # Shuffle image labels\n",
    "\n",
    "if feature_config == \"ASIFT\": # We need the keypoints of the description for ASIFT but not for SIFT\n",
    "    kp_shuffled = [img_kp[i] for i in idx] # Shuffle keypoints\n",
    "    train_kp_shuffled = kp_shuffled[:int(len(img_shuffled)*.80)] \n",
    "    vali_kp_shuffled = kp_shuffled[int(len(img_shuffled)*.80):]\n",
    "    \n",
    "# Train set (80%)\n",
    "train_features_shuffled = img_shuffled[:int(len(img_shuffled)*.80)]\n",
    "train_labels_shuffled = labels_shuffled[:int(len(labels_shuffled)*.80)]\n",
    "\n",
    "# Validation set (20%)\n",
    "vali_features_shuffled = img_shuffled[int(len(img_shuffled)*.80):]\n",
    "vali_labels_shuffled = labels_shuffled[int(len(labels_shuffled)*.80):]\n",
    "\n",
    "# FLANN parameters\n",
    "k_nn = 2\n",
    "lowe_ratio = 0.7\n",
    "num_closest_matches = 5\n",
    "FLANN_INDEX_KDTREE = 1\n",
    "index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
    "search_params = dict(checks=50)   # or pass empty dictionary\n",
    "flann = cv2.FlannBasedMatcher(index_params,search_params)\n",
    "error = 0\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "for i in range(len(vali_features_shuffled)):   \n",
    "    print(i)\n",
    "    vali_descriptors = vali_features_shuffled[i] # Validation Sample\n",
    "\n",
    "    # stores 5 highest number of keypoint matches\n",
    "    best_num_matches = np.zeros(num_closest_matches, dtype='uint64')\n",
    "    \n",
    "    matches_index = np.zeros(num_closest_matches,dtype='uint64')\n",
    "    # stores 5 train images with highest number of keypoint matches\n",
    "    best_image_matches = np.zeros((num_closest_matches, IMG_HEIGHT, IMG_WIDTH, NUM_CHANNELS), dtype='uint8')\n",
    "    # stores  corresponding matching images \n",
    "    \n",
    "    for j in range(len(train_features_shuffled)):\n",
    "        # Training sample descriptor\n",
    "        train_descriptors = train_features_shuffled[j] # Training Sample\n",
    "        \n",
    "        # Skip to next training sample if less than 2 local features found, \n",
    "        if vali_descriptors is None or train_descriptors is None or \\\n",
    "            len(vali_descriptors) < k_nn or len(train_descriptors) < k_nn:\n",
    "                continue\n",
    "                                    ### FOR SIFT ###\n",
    "        if feature_config == \"SIFT\": \n",
    "            matches = flann.knnMatch(vali_descriptors, train_descriptors, k=k_nn) # Use FLAN for feature matching\n",
    "\n",
    "            # Create a mask to draw all good matches\n",
    "            matchesMask = []\n",
    "            # Store all good matches as per Lowe's Ratio test.\n",
    "            good = []\n",
    "            for m,n in matches:\n",
    "                if m.distance < lowe_ratio *n.distance:\n",
    "                    good.append(m)\n",
    "                    matchesMask.append([1,0]) # Match\n",
    "                else:\n",
    "                    matchesMask.append([0,0]) # Mismatch\n",
    "            num_matches = len(good)\n",
    "            \n",
    "                                    ### FOR ASIFT ###\n",
    "        elif feature_config == \"ASIFT\":\n",
    "            # Get keypoints for training and validation samples\n",
    "            kp1 = vali_kp_shuffled[i]\n",
    "            kp2 = train_kp_shuffled[j]\n",
    "            \n",
    "            if len(vali_descriptors) < k_nn or len(train_descriptors) < k_nn: # Skip if less than 2 features found\n",
    "                continue\n",
    "            # Use FLANN for feature matching\n",
    "            raw_matches = matcher.knnMatch(vali_descriptors, trainDescriptors = train_descriptors, k = k_nn) # Use FLANN for feature matching\n",
    "            \n",
    "            # Since the above line returns a lot of features, we filter the features.\n",
    "            p1, p2, kp_pairs = filter_matches(kp1, kp2, raw_matches) \n",
    "\n",
    "            if p1.shape[0] < 4 or p2.shape[0] < 4:\n",
    "                continue\n",
    "\n",
    "            H, status = cv2.findHomography(p1, p2, cv2.RANSAC, 5.0)\n",
    "            # Where H is the resulting single-strain matrix.\n",
    "            # status returns a list of feature points that represent successful matches.\n",
    "            # ptsA, ptsB are keypoints.\n",
    "            # The three parameters cv2.RANSAC, ransacReprojThreshold, maxIters are related to RANSAC.\n",
    "            # ransacReprojThreshold: Maximum reprojection error in the RANSAC algorithm to consider a point as an inlier. \n",
    "            # maxIters: The maximum number of RANSAC-based robust method iterations.\n",
    "            #print('%d / %d  inliers/matched' % (np.sum(status), len(status)))\n",
    "            \n",
    "            # Number of good matches\n",
    "            num_matches = np.sum(status)\n",
    "\n",
    "\n",
    "        # compares to closest matches and update as necessary\n",
    "        for k in range(num_closest_matches):\n",
    "            if num_matches >= best_num_matches[k]:\n",
    "                best_num_matches = np.insert(best_num_matches, k, num_matches, 0)\n",
    "                best_num_matches = np.delete(best_num_matches, -1, 0)\n",
    "                matches_index = np.insert(matches_index, k, j, 0)\n",
    "                matches_index = np.delete(matches_index, -1, 0)\n",
    "                #best_image_matches = np.insert(best_image_matches, k, train_image, 0)\n",
    "                #best_image_matches = np.delete(best_image_matches, -1, 0)\n",
    "                #circles_and_lines = np.insert(circles_and_lines, k, good_matches, 0)\n",
    "                #circles_and_lines = np.delete(circles_and_lines, -1, 0)\n",
    "                break\n",
    "    \n",
    "    # Calculate error\n",
    "    prediction = train_labels_shuffled[matches_index[0]] \n",
    "    actual = vali_labels_shuffled[i]\n",
    "    err = abs(actual[0]-prediction[0]) + abs(actual[1]-prediction[1])\n",
    "    error +=err\n",
    "    \n",
    "    print(\"MAE\",np.round(error/(i+1),2))\n",
    "    \n",
    "    print(\"Prediction:({},{}), Actual:({},{}),ERR{}\".\n",
    "          format(np.round(prediction[0],2),np.round(prediction[1],2),np.round(actual[0],2),np.round(actual[1],2),err))\n",
    "end = time.time()\n",
    "\n",
    "MAE = np.round(error/len(vali_features_shuffled),2)\n",
    "print(\"Time Taken\",end-start)\n",
    "print(\"MAE FOR {}:{}\".format(feature_config,MAE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f09ac5",
   "metadata": {},
   "source": [
    "### FEATURE MATCHING: MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae45d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if feature_config == \"ASIFT\" or feature_config == \"SIFT\":\n",
    "    print(\"Cannt use KNN with {}, please use a different descriptor\".format(feature_config))\n",
    "    assert(False)\n",
    "    \n",
    "if feature_config == \"VLAD\":\n",
    "    input_size = 4096\n",
    "elif feature_config == \"SS ROT\" or feature_config == \"SS WARP\":\n",
    "    input_size = 256\n",
    "\n",
    "    \n",
    "    \n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        layers.Input((input_size,)),\n",
    "        layers.Dense(300, activation='relu'),\n",
    "        layers.Dense(300, activation='relu'),\n",
    "        layers.Dense(2, activation='linear') #regression\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_absolute_error')\n",
    "start=time.time()\n",
    "history = model.fit(img_features, train_labels, verbose=1,\n",
    "                                               validation_split = 0.2, epochs=200, batch_size=100)\n",
    "end=time.time()\n",
    "\n",
    "print(\"Time Taken:\",end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b68ec81a",
   "metadata": {},
   "source": [
    "### FEATURE MATCHING: K NEAREST NEIGHBOURS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0856f311",
   "metadata": {},
   "outputs": [],
   "source": [
    "if feature_config == \"ASIFT\" or feature_config == \"SIFT\":\n",
    "    print(\"Cannt use KNN with {}, please use a different descriptor\".format(feature_config))\n",
    "    assert(False)\n",
    "start=time.time()\n",
    "#Shuffle data\n",
    "idx = np.random.randint(len(img_features), size=len(img_features))\n",
    "img_shuffled = [img_features[i] for i in idx]\n",
    "labels_shuffled = [train_labels[i] for i in idx]\n",
    "\n",
    "# Split into training (80%) and test set (20%)\n",
    "train_features_shuffled = img_shuffled[:int(len(img_shuffled)*.80)]\n",
    "train_labels_shuffled = labels_shuffled[:int(len(labels_shuffled)*.80)]\n",
    "\n",
    "vali_features_shuffled = img_shuffled[int(len(img_shuffled)*.80):]\n",
    "vali_labels_shuffled = labels_shuffled[int(len(labels_shuffled)*.80):]\n",
    "\n",
    "# Train\n",
    "neighbours_model = NearestNeighbors(n_neighbors=1, algorithm='brute', metric='euclidean').fit(train_features_shuffled)\n",
    "# Predict\n",
    "distances, indices = neighbours_model.kneighbors(vali_features_shuffled)\n",
    "\n",
    "test_labels = []\n",
    "err = 0 \n",
    "for i in range(len(indices)):\n",
    "               \n",
    "    prediction_index = indices[i][0]\n",
    "    p = train_labels_shuffled[prediction_index]\n",
    "    actual = vali_labels_shuffled[i]\n",
    "    \n",
    "    err += abs(actual[0] - p[0]) + abs(actual[1] - p[1])\n",
    "    \n",
    "    print(\"Predict{}, Actual{}, ERR{}\".format(p,actual,err))\n",
    "    \n",
    "MAE = err/len(indices)\n",
    "\n",
    "print(\"Mean Absolute Error:\",MAE)\n",
    "end=time.time()\n",
    "\n",
    "print(\"Time Taken\",end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60cb2df8",
   "metadata": {},
   "source": [
    "## OUTPUT CSV FILE FOR NETVLAD + KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a838ffd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if feature_config != \"VLAD\":\n",
    "    print(\"Please select NetVLAD as a feature extractor\")\n",
    "    assert(False)\n",
    "# Train\n",
    "neighbours_model = NearestNeighbors(n_neighbors=1, algorithm='brute', metric='euclidean').fit(img_features)\n",
    "# Predict\n",
    "netvlad_model = NetVLADModel(input_shape=(IMG_HEIGHT, IMG_WIDTH, NUM_CHANNELS)) # Define input layer\n",
    "\n",
    "netvlad_model.summary()\n",
    "netvlad_model.load_weights('checkpoint/netvlad_weights.h5')\n",
    "netvlad_model.build()\n",
    "test_features = netvlad_model.predict(test_images)\n",
    "distances, indices = neighbours_model.kneighbors(test_features)\n",
    "\n",
    "test_labels = []\n",
    "for i in indices:\n",
    "    label = train_img_labels[i[0]]\n",
    "    test_labels.append(label)\n",
    "    \n",
    "header = ['id', 'x', 'y']\n",
    "with open(ROOTPATH + 'predictions_netvlad_knn123.csv', 'w', newline='') as predictions:\n",
    "    writer = csv.writer(predictions)\n",
    "    writer.writerow(header)\n",
    "    for i in range(len(test_img_names)):\n",
    "        img_name = test_img_names[i]\n",
    "        x_val, y_val = test_labels[i]\n",
    "        data = [img_name, str(x_val), str(y_val)]\n",
    "        writer.writerow(data)\n",
    "    predictions.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d0933a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0f4660",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3864b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa732d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1dfa77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15481e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47058b54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11124a90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91692d76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f3ceac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98aad25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894e3f7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673d9907",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a900e3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
